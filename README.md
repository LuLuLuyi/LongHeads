# LongHeads: Multi-Head Attention is Secretly a Long Context Processor
[[paper](https://arxiv.org/abs/2402.10685)]
![schemes](figures/longheads.png)
## TODOs
We will release the code in the following order, please stay tuned!

- [x] Release core code of LongHeads.
- [ ] Release example code for usage.
- [ ] Release perplexity evaluation code.
- [ ] Release passkey retrieval evaluation code.
- [ ] Release code of LongHeads with efficient implementation.

## Citation

If you find LongHeads useful or relevant to your project and research, please kindly cite our paper:

```bibtex
@misc{lu2024longheads,
      title={LongHeads: Multi-Head Attention is Secretly a Long Context Processor}, 
      author={Yi Lu and Xin Zhou and Wei He and Jun Zhao and Tao Ji and Tao Gui and Qi Zhang and Xuanjing Huang},
      year={2024},
      eprint={2402.10685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
